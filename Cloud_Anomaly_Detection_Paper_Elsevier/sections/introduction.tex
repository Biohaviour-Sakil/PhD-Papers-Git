\section{Introduction}
\label{sec:introduction}
%\noindent Cloud computing has revolutionised the way computing services can be used. Recently, Cloud computing services have seen significant growth. 
\noindent Cloud computing services are becoming ever more popular. According to a report~\cite{gartner} from Gartner, Infrastructure as a Service (IaaS) will grow 24\% every year through 2022.
%has seen growth of more than 40\% in revenue every year since 2011. They also predict growth of more than 24\% every year through 2022 for IaaS. 
%Such a growth in Cloud services market has attracted various security attackers to exploit vulnerabilities in the Cloud in order to gain their personal benefits; they may perform different security attacks such as: insider attack, Denial of Service (DoS) or Distributed Denial of Service (DDoS) attack, user to root attack, port scanning, attacks on virtualisation, backdoor channel attacks, etc~\cite{cloud_ids_survey:2016}. 
Such a growth in the Cloud services market has attracted various cybersecurity attackers to exploit vulnerabilities in the Cloud in order to gain personal benefit. %The attackers attempt to launch various attacks in the Cloud, amongst which DDoS and cryptomining attacks are gaining the 
Amongst the various cybersecurity attacks in the Cloud, DDoS and cryptomining attacks are growing sharply. 
%Amongst these attacks, DDoS and backdoor channel attacks are growing sharply. 
%\noindent Cloud services are becoming ever more popular. According to a report\footnote{http://www.gartner.com/newsroom/id/3354117} from Gartner, Infrastructure as a Service (IaaS) has seen growth of more than 40\% in revenue every year since 2011. They also predict growth of more than 25\% every year through 2019 for IaaS. 
%In spite of such growth in the Cloud services market, many users and organisations face barriers in adopting the Cloud due to security concerns.
%Cloud security attacks can be grouped into six categories~\cite{cloud_ids_survey:2016}: insider attack, Denial of Service (DoS) or Distributed Denial of Service (DDoS) attack, user to root attack, port scanning, attacks on virtualisation, and backdoor channel attacks. 
%Amongst these attacks, DDoS and backdoor channel attacks are growing sharply. 
In the Cloud, DDoS attacks typically attempt to overwhelm the Virtual Machine (VM) network by sending large amount of network packets from multiple hosts, so that the VM cannot serve its legitimate users' requests for various services such as web application, media streaming application, etc. 
%DDoS attacks typically target those VMs which run a web service or a media streaming application in order to interrupt their 
%in order to interrupt Cloud services which are otherwise dedicated to the users. 
Whereas, cryptomining attacks gain remote access to the VM in order to use its CPU computing power to perform cryptocurrency mining, which in turn interrupts legitimate users' computation on the VM. 
%\textbf{Backdoor channel attacks} gain remote access to the victimised VM in order to use its resources to launch various attacks such as cypto-mining or DDoS. 
According to a report~\cite{cisco} from Cisco, DDoS attacks 
%with size greater than 1 Gbps increased by 172\% in 2016 (1.3 million attacks in 2016) and they predict that the attacks 
will increase to 3.1 million by 2021. 
%Most recently, on February 28, 2018 the Github website was hit by the largest-ever DDoS attack\footnote{https://thehackernews.com/2018/03/biggest-ddos-attack-github.html} (1.35 Tbps).
%Due to the rising value of cryptocurrency, cryptomining attacks increased six-fold during the period January-August 2017, as reported in Infosecurity magazine\footnote{https://www.infosecurity-magazine.com/news/ibm-cryptomining-attacks-increased/}. Most importantly, 
Cloud environments are very much vulnerable to cryptomining attacks due to the auto-scaling nature of the Cloud which allows the attackers to automatically spawn more VMs, i.e. more CPUs for the cryptomining task. This is evident from the cryptomining attack~\cite{tesla} on electric vehicle maker Tesla's Cloud environment. 

To successfully deny legitimate users access to the Cloud services and to perform cryptocurrency mining, both DDoS and cryptomining attacks significantly consume the network bandwidth and the CPU of the Cloud VMs, respectively. This results in significant deviation in the normal network and CPU usage pattern of the VMs, which can be defined as VM-level anomaly. Hence, anomaly detection techniques can be used to identify DDoS and the cryptomining attacks in the Cloud. Researchers have proposed various anomaly detection techniques for Cloud which use machine learning or statistical approaches. The anomaly detection systems proposed in~\cite{ml_based:2012, Pandeeswari2016, ML_based_ids:2016} use supervised machine learning algorithms. These algorithms require both the ``normal" and the ``anomalous" behaviour traces to build the learning models, which can detect the anomalies. 
%In a Cloud data centre, ``normal" traces can be prepared easily by monitoring the VMs' resource utilisation in the situation where the VMs are believed to be anomaly-free; however, ``anomalous" traces need to be generated artificially using emulation or collected from online repositories. 
The algorithms may fail to detect anomalies arising due to unknown DDoS or cryptomining attacks, traces of which are not recorded by the learning models or which have very different patterns from the learned ``anomalous" patterns. To solve this problem researchers in~\cite{automated-detection:2016, UBL:2012, cloud-malware:2016} have proposed unsupervised learning and one class classification algorithms such as K-Means, Self Organising Map (SOM), and one class Support Vector Machine (SVM). 
These algorithms build the learning models by using the ``normal" behaviour traces. The models can identify anomalies by observing the deviation in the ``normal" behaviour pattern and as a result, these algorithms can successfully detect zero-day or unknown attacks.
%These algorithms learn only from the ``normal" behaviour traces and do not use the ``anomalous" traces, and as a result, they can successfully detect zero-day or unknown attacks which impose significant deviation in the ``normal" behaviour pattern. 
Although the unsupervised learning and one class classification algorithms improve the accuracy of anomaly detection along with the ability to detect zero-day attacks, these algorithms may exhibit false positives arising due to workload spikes in a Cloud data centre. We can consider these spikes as genuine workload spikes which do not follow the ``normal" workload trend and their values are significantly higher than the other values in the workload data set. 
It is important to note that the genuine workload spikes persist only for a momentary period of time and this differentiates them from the anomalies (high utilisation values) due to DDoS and cryptomining attacks, which persist for a relatively long period of time.
%Its important to note here that the genuine workload spikes persist only for momentary period of time and this differentiates them from the high utilisation values due to DDoS or cryptomining attacks, which persist for a relatively long period of time.
%\textcolor{red}{In case of a large-scale Cloud data centre, an anomaly detection system may generate significant amount of false positives due to the workload spikes. 
%\textcolor{red}{In case of a large-scale Cloud data centre, the VMs may experience large volume of genuine workload spikes may be 
%\textcolor{red}{A large-scale Cloud data centre may experience large volume of genuine workload spikes. 

In order to understand whether the VMs hosted in a real-world Cloud data centre experience workload spikes, we analysed real-world Cloud workload traces~\cite{workloadCCGRID:2015} collected from a Cloud data centre named Bitbrains\footnote{https://www.solvinity.com}. The traces contain seven performance metrics including CPU utilisation and network throughput of 1,750 VMs.
%This is evident from our analysis of real-world Cloud workload traces~\cite{workloadCCGRID:2015} collected from a Cloud data centre named Bitbrains\footnote{https://www.solvinity.com}. }The traces contain seven performance metrics including CPU utilisation and network throughput of 1,750 VMs.
%In order to understand how frequent these spikes may arise in the Cloud, we analysed real-world Cloud workload traces~\cite{workloadCCGRID:2015} collected from a Cloud data centre named Bitbrains\footnote{https://www.solvinity.com}. The traces contain seven performance metrics including CPU utilisation and network throughput of 1,750 VMs.
%\textcolor{red}{In order to understand the impact of the workload spikes}, we analysed real-world Cloud workload traces~\cite{workloadCCGRID:2015} collected from a Cloud data centre named Bitbrains\footnote{https://www.solvinity.com}. The traces contain seven performance metrics including CPU utilisation and network throughput of 1,750 VMs.
%The analysis for spike detection was performed by using the Interquartile Range (IQR\footnote{https://en.wikipedia.org/wiki/Interquartile\_range}) algorithm.
We performed a spike detection analysis by using the Interquartile Range (IQR\footnote{https://en.wikipedia.org/wiki/Interquartile\_range}) algorithm.
From the analysis of one month of the trace data from~\cite{workloadCCGRID:2015}, we observe that 84\% of VMs show spikes in their CPU utilisation at least once in the experimental month, whereas 95\% of VMs show spikes in their network traffic at least once in the same time period. 
From this finding we can assume that an anomaly detection system deployed in a large-scale Cloud data centre may raise frequent false positives due to the workload spikes. Receiving false positive alarms on a frequently is a major demerit of anomaly detection tools designed for the Cloud for a number of reasons such as waste of operators' time by engaging them in unnecessary investigations, unwanted interruption of Cloud services, etc. 
%Also, its found that 1.7\% and 3\% of samples generate spikes in the case of CPU utilisation and network traffic, respectively.
%This finding motivates for a solution to remove the false positives in the anomaly detection systems, which arise due to the workload spikes in the Cloud. 
This motivates a solution to remove false positives from the anomaly detection systems designed for the Cloud. 
Researchers in~\cite{automated-detection:2016}, \cite{UBL:2012}, \cite{cloud-malware:2016} consider window-based averaging on the raw data to reduce false positives. The works in~\cite{EbAT:2010} and \cite{entorpy_based_detection_2:2014} consider entropy-based anomaly detection which also reduces the number of false positives. However, these approaches may still generate false positives in certain scenarios for certain use cases, which we explain in the next section.
%Researchers in~\cite{automated-detection:2016}, \cite{UBL:2012}, \cite{cloud-malware:2016} use averaging on the raw data as a data pre-processing approach to reduce false positives. The works in~\cite{EbAT:2010} and \cite{entorpy_based_detection_2:2014} consider entropy analysis in their anomaly detection systems which also reduces the number of false positives. However, these approaches may still generate false positives in certain scenarios for certain use cases, which we explain in the next section.

In this paper, we propose a Real-time Anomaly Detection System (RADS) for Cloud data centres, which can detect VM-level anomalies occurring due to unknown DDoS and cryptomining attacks. 
%RADS uses One Class Classification (OCC)~\cite{OCC:2008} based algorithm that learns the ``normal" pattern of the VMs' CPU and network usage. 
RADS uses a One Class Classification (OCC)~\cite{OCC:2008} based algorithm that learns the ``normal" pattern of CPU and network usage of each of the hosted VMs. 
%The algorithm basically builds OCC model for each of the hosted VMs.
%``normal" behaviour trace, RADS considers CPU utilisation and network traffic data collected from the VMs running the benign Cloud applications which are not affected by any cybersecurity attack. 
%Importantly, we assume that each VM is running a single Cloud application and this assumption is correct for various Cloud applications, which implement web servers, databases, data analytics, search engines, media streaming servers, etc.  
%Thus, the algorithm builds VM-specific OCC models. 
The algorithm flags an anomaly whenever a VM's CPU or network usage pattern deviates significantly from its ``normal" pattern. 
%Thus, RAIDS performs \textit{application specific learning} to detect the intrusions specific to the applications. 
%For reducing the false positives, RADS considers a window-based pre-processing of the raw data before they are used as the training data for building the OCC models or as the test sample for detecting the anomalies. 
%\textcolor{red}{To deal with the false positives, RADS combines average and standard deviation of the raw data in a window-based time series analysis.
To deal with the false positives, RADS combines average and standard deviation of the raw data in a window-based time series analysis.
%Also, RADS uses a training optimisation algorithm that dynamically decides the training duration for each of the VM-specific classification models. 
%required for building the VM-specific classification models. 
%This algorithm is very important considering the fact that in a Cloud data centre, the VMs host diverse workloads and a fixed duration of training data for all the VM-specific classification models may result in poor performance for RADS. }
%Therefore, RADS uses a training optimisation algorithm that dynamically decides the minimum training duration required for building the VM-specific classification models. 
Specifically, we make the following \textbf{key contributions} in this paper:
\begin{enumerate}[{(1)}]
%\item RAIDS provides an algorithm based on probabilistic classification for detecting anomalies in cloud applications. The accuracy of the algorithm is examined using different virtual machines running various services from the CloudSuite workload collection. The proposed algorithm utilises probability distribution analysis on the raw data (??) to detect anomalies and minimise false positives.
%\item \textcolor{red}{We propose a new intrusion detection algorithm for Cloud that provides high accuracy and low false positives in detecting Cloud security attacks such as DDoS and backdoor channel attacks.}
\item We propose RADS for Cloud data centres which achieves high accuracy and low false positive rate in detecting VM-level anomalies occurring due to unknown DDoS and cryptomining attacks. RADS can operate in real-time, meaning that it can monitor each VM hosted in the Cloud data centre in real-time and detect the attacks as they appear inside the VMs.
%\item \textcolor{red}{We propose a novel training optimisation algorithm that dynamically decides the training duration for each of the VM-specific classification models. 
\item We propose a novel training optimisation algorithm that decides the optimal amount of training data to be used for building the VM-specific classification models. This helps in achieving real-time dynamic training for RADS as opposed to offline static training which uses a fixed amount of training data. This is important considering the fact that in a Cloud data centre, the VMs host diverse workloads and a fixed amount of training data for all the VM-specific classification models may result in poor performance for RADS.
%The algorithm is very important considering the fact that in a Cloud data centre, the VMs host diverse workloads and a fixed amount of training data for all the VM-specific classification models may result in poor performance for RADS. }
%Also, we propose a training optimisation algorithm that dynamically decides the training duration for building the classification models. 
%As we propose RADS for detecting anomalies that may occur on the hosted VMs, we  
%In a Cloud data centre, the VMs host diverse workloads and as a result, a fixed duration of training data for all the VM-specific classification models may result in poor performance for RADS. Therefore, we propose a training optimisation algorithm that dynamically decides the minimum training duration required for building the VM-specific classification models. 
%deal with the dynamic nature of the Cloud workloads, RADS performs real-time dynamic training of the OCC models where the models get updated in real-time at regular intervals until they start performing accurately. 
%Moreover, to deal with the dynamic nature of the Cloud workloads, RADS performs real-time dynamic training of the OCC models where the models get updated in real-time at regular intervals until they start performing accurately. 
 %\textbf{Dynamically deciding training duration.} Due to the dynamic nature of Cloud applications, it is required to dynamically decide the training duration for the behavioural models based on the behaviour of the applications. Static models, which are built with fixed training duration may result in low detection accuracy due to model overfitting or underfitting issues. 
%Static models, which are built with fixed training duration may result in low detection accuracy due to model overfitting or underfitting issues. 
%To achieve this, RADS applies a heuristic that dynamically decides the training duration for each OCC model.
%Moreover, RADS performs real-time training of the OCC models where the models get updated in real-time at regular intervals until they start performing accurately. To achieve this, RADS applies a heuristic that dynamically decides the training duration for each OCC model.
%, which is based on the performance of the models in real-time. 
 %\textbf{Dynamically deciding training duration.} Due to the dynamic nature of Cloud applications, it is required to dynamically decide the training duration for the behavioural models based on the behaviour of the applications. Static models, which are built with fixed training duration may result in low detection accuracy due to model overfitting or underfitting issues. 
%The model is updated with the normal behavioural data sets until it achieves a stable state. A stable state for the model is realised by checking whether the model is identifying the normal behavioural pattern accurately without any false positives for a significant period of time. This period varies depending on the type of the cloud application.
%To achieve real-time detection with low detection latency and scalability on large-scale Cloud data centres, RAIDS performs the model training and the intrusion detection on the hosting nodes locally. 
%\item We evaluate the performance of RADS by running lab-based experiments in an OpenStack\footnote{https://www.openstack.org} based Cloud data centre, which hosts two representative Cloud applications collected from the CloudSuite\footnote{http://cloudsuite.ch} benchmark suite. We emulate the DDoS and the cryptomining attacks by running microbenchmarks. Evaluation results show that RADS can detect anomalies occurring due to DDoS and cryptomining attacks, with an accuracy of 90-95\% and a low false positive rate of 0-3\%. The results further reveal on average 34\% improvement in accuracy and 60\% improvement in false positive rate while using the combination of both the average and standard deviation in the data pre-processing phase instead of using only average or entropy.
\item We evaluate the performance of RADS by running lab-based experiments in an OpenStack\footnote{https://www.openstack.org} based Cloud data centre. We emulate the DDoS and the cryptomining attacks by running microbenchmarks. Evaluation results show that RADS can detect VM-level anomalies with an accuracy of 90-95\% and a low false positive rate of 0-3\%. The results further reveal on average 34\% improvement in accuracy and 60\% improvement in false positive rate when RADS uses its window-based time series analysis instead of using the state-of-the-art average~\cite{automated-detection:2016}, \cite{UBL:2012}, \cite{cloud-malware:2016} or entropy~\cite{EbAT:2010}, \cite{entorpy_based_detection_2:2014} based analysis. 
%\item We evaluate the performance of RADS by running lab-based experiments in an OpenStack\footnote{https://www.openstack.org} based Cloud data centre, which hosts two representative Cloud applications collected from the CloudSuite\footnote{http://cloudsuite.ch}. We emulate the DDoS and the cryptomining attacks by using microbenchmarks. Evaluation results show that RADS can achieve 90-95\% accuracy with a low false positive rate of 0-3\%. The results further reveal on average 34\% improvement in accuracy and 60\% improvement in false positive rate while using the combination of both the average and standard deviation in the data pre-processing phase instead of using only average or entropy.
\item We further validate the performance of RADS in terms of false positive rate by analysing real-world Cloud workload traces~\cite{workloadCCGRID:2015} collected from a Cloud data centre named Bitbrains. The analysis results demonstrate that RADS experiences fewer false positives when using its window-based time series analysis in comparison to using average~\cite{automated-detection:2016}, \cite{UBL:2012}, \cite{cloud-malware:2016} or entropy~\cite{EbAT:2010}, \cite{entorpy_based_detection_2:2014} based analysis.
%\item We further validate the performance of RADS in terms of false positive rate by analysing real-world Cloud workload traces~\cite{workloadCCGRID:2015} collected from a Cloud data centre named Bitbrains. \textcolor{red}{The analysis results demonstrate that RADS experiences fewer false positives while using the combination of both the average and standard deviation in the data pre-processing phase in comparison to using only average or entropy. }
%\item \textcolor{red}{We propose a heuristic for \textit{dynamically deciding training duration} required for building the OCC models. Our work is the first to explicitly address the challenge of \textit{dynamically deciding training duration} for Cloud IDSs. }
%, which updates the models with the normal behavioural data sets until they achieve a stable state. A stable state for a specific model is realised by checking whether the model is identifying the normal behavioural pattern accurately without any false positives for a significant period of time. This period varies depending on the type of the cloud applications.
\end{enumerate}

The remainder of the paper is organised as follows. Section~\ref{sec:problem_definition} defines the problems with the existing approaches in Cloud anomaly detection.
Section~\ref{sec:approach} demonstrates RADS window-based time series analysis. Section~\ref{sec:overview} and \ref{sec:framework} give an overview of RADS and discuss the RADS framework in detail, respectively. 
Section~\ref{sec:experiments} presents experimental results and discusses them. 
Section~\ref{sec:related_work} presents related work in Cloud anomaly detection which use different types of machine learning algorithms.
Finally, Section~\ref{sec:conclusions} concludes the paper. 
